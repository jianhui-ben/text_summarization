{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562971</td>\n",
       "      <td>I love these cookies!  Not only are they healt...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562972</td>\n",
       "      <td>Quaker Soft Baked Oatmeal Cookies with raisins...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562973</td>\n",
       "      <td>I am usually not a huge fan of oatmeal cookies...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562974</td>\n",
       "      <td>I participated in a product review that includ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562975</td>\n",
       "      <td>My kids loved these. I was very pleased to giv...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                               Text  Score\n",
       "0  562971  I love these cookies!  Not only are they healt...      5\n",
       "1  562972  Quaker Soft Baked Oatmeal Cookies with raisins...      5\n",
       "2  562973  I am usually not a huge fan of oatmeal cookies...      5\n",
       "3  562974  I participated in a product review that includ...      5\n",
       "4  562975  My kids loved these. I was very pleased to giv...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"Amazon_review_data/Reviews.csv\")\n",
    "reviews['ProductId']=reviews['ProductId'].astype(str)\n",
    "df=reviews[reviews['ProductId']==\"B007JFMH8M\"]  ## the most popular cookie\n",
    "df = df.reset_index(drop=True)\n",
    "df= df[['Id', 'Text', 'Score']]\n",
    "sentences=df.Text.values\n",
    "labels= df.Score.values -1  ### here is important. because the BERT classification requires the label category start from 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the bert model\n",
    "model = BertModel.from_pretrained('bert-base-uncased') #cache_dir='some path that I want to download the model'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) #output_hidden_states=True, output_attentions=True\n",
    "# input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([804.,  90.,  10.,   5.,   2.,   1.,   0.,   0.,   0.,   1.]),\n",
       " array([  21. ,  122.6,  224.2,  325.8,  427.4,  529. ,  630.6,  732.2,\n",
       "         833.8,  935.4, 1037. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_counts=[len(tokenizer.tokenize(sent)) for sent in sentences]\n",
    "print(sum(np.array(tokens_counts)>256))\n",
    "plt.hist(tokens_counts)  ## most texts is shorted than 400 tokens, we select 256 as the max_len of our sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  I love these cookies!  Not only are they healthy but they taste great and are so soft!  I will definitely add these to my grocery list!\n",
      "Tokenized:  ['i', 'love', 'these', 'cookies', '!', 'not', 'only', 'are', 'they', 'healthy', 'but', 'they', 'taste', 'great', 'and', 'are', 'so', 'soft', '!', 'i', 'will', 'definitely', 'add', 'these', 'to', 'my', 'grocery', 'list', '!']\n",
      "Token IDs:  [1045, 2293, 2122, 16324, 999, 2025, 2069, 2024, 2027, 7965, 2021, 2027, 5510, 2307, 1998, 2024, 2061, 3730, 999, 1045, 2097, 5791, 5587, 2122, 2000, 2026, 13025, 2862, 999]\n",
      "Token IDs aftern encoding:  [101, 1045, 2293, 2122, 16324, 999, 2025, 2069, 2024, 2027, 7965, 2021, 2027, 5510, 2307, 1998, 2024, 2061, 3730, 999, 1045, 2097, 5791, 5587, 2122, 2000, 2026, 13025, 2862, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "input_token_ids=[]\n",
    "for sent in sentences:\n",
    "    input_token_ids.append(tokenizer.encode(sent,                         \n",
    "                            max_length = 256))      # Truncate all sentences.\n",
    "#                             return_tensors = 'pt'))     # Return pytorch tensors.\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
    "\n",
    "## tokenize.encode can handle both two steps above, and then add special tokens [start] and [end]\n",
    "print('Token IDs aftern encoding: ', tokenizer.encode(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  256\n",
      "Min sentence length:  23\n"
     ]
    }
   ],
   "source": [
    "## max length of the reviews:\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_token_ids]))\n",
    "print('Min sentence length: ', min([len(sen) for sen in input_token_ids]))  ##padding has not been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 256 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Padding added done\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids=[]\n",
    "for sent in input_token_ids:\n",
    "    input_ids.append(F.pad(torch.tensor(sent, dtype=torch.long), (0, int(MAX_LEN-len(sent))), \"constant\", 0))\n",
    "print('\\nPadding added done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(torch.tensor(np.array(att_mask), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=110, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=110, test_size=0.1)\n",
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.stack(train_inputs)  ##convert a list of tensors into a tensor\n",
    "validation_inputs = torch.stack(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long) ## convert an array to a tensor\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "\n",
    "train_masks = torch.stack(train_masks)\n",
    "validation_masks = torch.stack(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 6, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# model.cuda() same thing\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (6, 768)\n",
      "classifier.bias                                                 (6,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9a5096a438>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the purposes of fine-tuning, the authors recommend choosing from the following values:\n",
    "# - Batch size: 16, 32  (We chose 32 when creating our DataLoaders).\n",
    "# - Learning rate (Adam): 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
    "# - Number of epochs: 2, 3, 4  (We'll use 4).\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "#'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 3e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps =1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "##plot the lrs\n",
    "lrs=[]\n",
    "for i in range(100):\n",
    "    lrs.append(scheduler.get_lr()) \n",
    "    scheduler.step()\n",
    "plt.plot(range(100), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the training and evaluation loop:\n",
    "\n",
    "Training loop:\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "Evalution loop:\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "So please read carefully through the comments to get an understanding of what's happening. If you're unfamiliar with pytorch a quick look at some of their [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) will help show you that training loops really involve only a few simple steps; the rest is usually just decoration and logging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:50.\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.26\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.26\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:26.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss: 1.55\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.26\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss: 1.56\n",
      "  Training epcoh took: 0:01:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.26\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "## the training loop is based on\n",
    "## https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "seed_val = 10\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 10 batches. (one epoch has 26 batches)\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0] # (loss), logits, (hidden_states), (attentions) \n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvoAAAGaCAYAAAB+A+cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeVhV5cL+8e/eTA6AAoIDIooDIooKMjiUZqlp5phmOeSUVvaeU9npWMdUtPJUdk7Dm/WqiFqaqWmm2eSQZaIo4jwjCqgo4oAMIrD5/dFPziE0RYG1gftzXf6x11577XvzXODN4lnPMuXn5+cjIiIiIiIVitnoACIiIiIiUvJU9EVEREREKiAVfRERERGRCkhFX0RERESkAlLRFxERERGpgFT0RUREREQqIBV9ERG5paSkJHx9ffnoo4/u+hiTJk3C19e3BFPdHV9fXyZNmmR0DBGRMmNrdAAREblzxSnMGzZsoH79+qWYRkRErJlJN8wSESk/Vq9eXehxTEwMX375JY8//jhBQUGFnuvWrRvVqlW7p/fLz8/n+vXr2NjYYGt7d+eGcnJysFgsODg43FOWe+Xr60v//v355z//aWgOEZGyojP6IiLlSN++fQs9zsvL48svv6RNmzZFnvuj9PR0HB0di/V+JpPpngu6nZ3dPb1eRETujuboi4hUQF27dmX48OEcPHiQMWPGEBQURJ8+fYDfC/+///1vBg0aRGhoKC1btqRbt27MmjWLrKysQse52Rz9/962adMmBg4cSKtWrejUqRNvv/02ubm5hY5xszn6N7ZdvXqVqVOn0r59e1q1asWQIUPYs2dPkc9z6dIlXn31VUJDQ2nbti0jRozg4MGDDB8+nK5du97T12r58uX079+fgIAAgoKCGD16NDt37iyy388//8ywYcMIDQ0lICCALl268PzzzxMfH1+wz9mzZ3n11Vd54IEHaNmyJe3bt2fIkCGsWrXqnjKKiNwNndEXEamgzpw5w1NPPcXDDz9M9+7dyczMBODcuXOsWLGC7t2707t3b2xtbYmOjmbevHkcOnSIiIiIOzr+5s2bWbJkCUOGDGHgwIFs2LCB+fPnU6NGDZ555pk7OsaYMWNwdXVlwoQJXL58mcjISMaNG8eGDRsK/vpw/fp1Ro0axaFDhxgwYACtWrXiyJEjjBo1iho1atzdF+f/e/fdd5k3bx4BAQG89NJLpKens2zZMp566ilmz55N586dAYiOjubZZ5+ladOmjB8/HicnJ86fP09UVBQJCQk0atSI3NxcRo0axblz53jyySdp2LAh6enpHDlyhJ07d9K/f/97yioiUlwq+iIiFVRSUhJvvPEGgwYNKrTdy8uLn3/+udCUmqFDh/L+++/zySefsHfvXgICAm57/OPHj7N27dqCC36feOIJHn30UT7//PM7LvotWrRg2rRpBY8bN27MCy+8wNq1axkyZAjw+xn3Q4cO8cILL/Dss88W7NusWTOmT5+Op6fnHb3XH504cYKIiAgCAwNZuHAh9vb2AAwaNIhHHnmE8PBwfvrpJ2xsbNiwYQMWi4XIyEjc3NwKjjFhwoRCX4/4+Hhefvllnn766bvKJCJSkjR1R0SkgqpZsyYDBgwost3e3r6g5Ofm5nLlyhUuXrxIhw4dAG46deZmHnzwwUKr+phMJkJDQ0lJSSEjI+OOjjFy5MhCj8PCwgA4depUwbZNmzZhY2PDiBEjCu07aNAgnJyc7uh9bmbDhg3k5+czduzYgpIPULt2bQYMGMDp06c5ePAgQMH7/PDDD0WmJt1wY5/t27eTmpp617lEREqKzuiLiFRQXl5e2NjY3PS5xYsXs3TpUo4fP47FYin03JUrV+74+H9Us2ZNAC5fvkz16tWLfQwXF5eC19+QlJSEh4dHkePZ29tTv3590tLS7ijvHyUlJQHQtGnTIs/d2JaYmEirVq0YOnQoGzZsIDw8nFmzZhEUFMR9991H7969cXV1BcDT05NnnnmGOXPm0KlTJ/z8/AgLC+Phhx++o7+QiIiUNJ3RFxGpoKpWrXrT7ZGRkUyfPh0PDw+mT5/OnDlziIyMLFh28k5XXb7VLxElcQxrW/nZxcWFFStWsGjRIoYPH05GRgYzZ86kR48exMbGFuz34osv8uOPP/Laa6/h5eXFihUrGDRoEO+++66B6UWkstIZfRGRSmb16tV4enoyd+5czOb/nO/55ZdfDEx1a56enkRFRZGRkVHorH5OTg5JSUk4Ozvf1XFv/DXh2LFjNGjQoNBzx48fL7QP/P5LSWhoKKGhoQAcPnyYgQMH8sknnzBnzpxCxx0+fDjDhw8nOzubMWPGMG/ePEaPHl1ofr+ISGnTGX0RkUrGbDZjMpkKnTXPzc1l7ty5Bqa6ta5du5KXl8eiRYsKbV+2bBlXr169p+OaTCYiIiLIyckp2H7+/HlWrlyJp6cnLVq0AODixYtFXu/j44ODg0PBVKerV68WOg6Ag4MDPj4+wJ1PiRIRKSk6oy8iUsk8/PDDvPfeezz99NN069aN9PR01q5de9d3vi1tgwYNYunSpbz//vskJCQULK/5/fff4+3tfcuLY2/Hx8en4Gz7sGHD6NmzJxkZGSxbtozMzExmzZpVMLXo9ddfJzk5mU6dOlGvXj2uXbvGd999R0ZGRsGNyrZv387rr79O9+7dadSoEdWrV2f//v2sWLGC1q1bFxR+EZGyYp0/1UVEpNSMGTOG/Px8VqxYwZtvvom7uzs9e/Zk4MCB9OrVy+h4Rdjb27Nw4ULeeecdNmzYwHfffUdAQAALFizgH//4B9euXbvrY//tb3/D29ubJUuW8N5772FnZ0fr1q157733aNeuXcF+ffv2ZeXKlaxatYqLFy/i6OhIkyZN+PDDD+nRowcAvr6+dOvWjejoaNasWYPFYqFu3bqMHz+e0aNH3/PXQUSkuEz51nbFk4iIyB3Iy8sjLCyMgICAO77Jl4hIZaI5+iIiYvVudtZ+6dKlpKWl0bFjRwMSiYhYP03dERERqzd58mSuX79O27Ztsbe3JzY2lrVr1+Lt7c3gwYONjiciYpU0dUdERKze119/zeLFizl58iSZmZm4ubnRuXNn/vrXv1KrVi2j44mIWCUVfRERERGRCkhz9EVEREREKiAVfRERERGRCkgX45aiS5cysFjKdmaUm5sjqanpZfqecnsaF+ujMbFOGhfrozGxThoX62PEmJjNJlxcqt/yeRX9UmSx5Jd50b/xvmJ9NC7WR2NinTQu1kdjYp00LtbH2sZEU3dERERERCogFX0RERERkQpIRV9EREREpAJS0RcRERERqYBU9EVEREREKiAVfRERERGRCsjQon/+/HlmzZrF8OHDadu2Lb6+vmzfvv2OXjtp0iR8fX2L/Bs8ePBN94+Pj+eFF14gLCyMgIAAevbsydy5c295/PT0dDp27Iivry/r16+/q88nIiIiImIUQ9fRj4+PZ+7cuXh7e+Pr60tsbGyxXl+1alXCw8MLbXN1dS2y34EDBxgxYgQ+Pj6MHz+e6tWrk5iYSHJy8i2P/fHHH5OZmVmsPCIiIiIi1sLQou/v78+2bdtwcXFh/fr1TJgwoVivt7W1pW/fvn+6T15eHq+88grt27fnww8/xGy+/R8x4uPj+eyzz3jmmWf46KOPipVJRERERMQaGFr0HR0d7/kYeXl5ZGVl3fJYW7Zs4fjx4wUlPyMjg6pVq/5p4Z85cyYPPPAAwcHB95yvrEQdSGbl5jgupmXj6uzAgM6Nae9fx+hYIiIiImKQcn0xbkZGBkFBQQQFBREaGsrMmTPJzs4utE9UVBSOjo6cO3eOHj16EBgYSGBgIJMnTyYrK6vIMTdv3szWrVv529/+VlYf455FHUhm4XeHSU3LJh9ITctm4XeHiTpw66lJIiIiIlKxGXpG/164u7szduxY/Pz8sFgsbNq0iQULFhAXF8e8efMK9jt16hR5eXk899xzDBw4kIkTJxIbG0tkZCQXL15k9uzZBfvm5OTw1ltvMXz4cBo0aMDZs2eN+GjFtnJzHNdzLYW2Xc+1sHJznM7qi4iIiFRS5bboT5w4sdDj3r17U7t2bSIiIvjtt9/o2LEjAJmZmWRlZTFkyBBef/11ALp3747JZCIiIoLDhw/TvHlzABYtWsSVK1d49tlnSySjm9u9T026ExfTsm+53d3dqUwyyO1pLKyPxsQ6aVysj8bEOmlcrI+1jUm5Lfo3M3r0aCIiIoiKiioo+lWqVAF+/0Xgv/Xp04eIiAhiYmJo3rw5Fy5cYPbs2bz00ks4OzuXSJ7U1HQslvwSOdafcXV2IPUmZd/O1kx8wkUcq9qVegb5c+7uTqSkXDU6hvwXjYl10rhYH42JddK4WB8jxsRsNv3pieVyPUf/j2rVqoWdnR1Xrlwp2Obu7g6Am5tboX1vPE5LSwPg008/xcnJiU6dOpGUlERSUhIXLlwAIDU1laSkJPLzS7+0340BnRtjb1t4KG3MJnJyLUyJ2M6B+IsGJRMRERERo1SoM/rJycnk5OQUWkvf39+f5cuXc+7cOXx8fArtC/9Zd//MmTOcPXuW7t27FznulClTANi7dy8ODg6l+RHuyo15+H9cdaeeW3XmrDnAe1/upls7Lx7r4oOdrY3BaUVERESkLJSLop+QkABAgwYNAMjOziYnJ6fIkpo3Lqzt1KlTwbauXbvy5ptvsmLFCtq3b1+wffny5ZhMJsLCwgAYP348AwYMKHS8o0eP8sEHHzBu3Dhat26NnZ31ToFp71+H9v51ivzZaMrIYJZvOs5POxM5eOoi4x71x8ujbK4dEBERERHjGF70b5TzuLg4AFavXk1MTAzOzs4MGzYMgJEjRwKwceNGAFJSUujfvz+9e/fGx8enYNWdqKgoevXqVWj9+9q1azNu3Dg+/vhjcnJyCAsLIzY2lm+++YYnn3wSb29vAFq3bl0km5OTU8FzDz30UOl8AUqZg50Nw7r7EtDYjfnrDjNj4Q4Gdm5Mt2AvzCaT0fFEREREpJQYXvQ/+OCDQo+/+uorADw9PQuK/h85OzvTpUsXfvvtN1atWoXFYqFhw4ZMmjSJESNGFNn/f/7nf3B2dmbJkiVs3LgRDw8PXnjhBcaPH1/yH8hKBTSuxfQxISxYd5gvNx5nb1wqY3u3wMXJ+qYiiYiIiMi9M+Vb6xWmFUBZrbrz3253xXd+fj6/7DnDFxuOYWdj5qmHm9OuuUcZJqyctDqC9dGYWCeNi/XRmFgnjYv10ao7YjiTyUTnNp5MGxWCh0tVZn+9n4hvD5KVnWt0NBEREREpQSr6lVQd12q8OiyI3h0asnV/MlPnR3Ms6bLRsURERESkhKjoV2K2NmYG3O/DpKGBAPxz8S5W/nKC3DyLwclERERE5F6p6AtN69ckfHQIHfzrsHbrSWZ+votzFzONjiUiIiIi90BFXwCo6mDLmN4teLZfS85fymRqZDSbd5+22rsBi4iIiMifU9GXQoKbexA+OoTG9Wqw8Psj/O/KfaRlXjc6loiIiIgUk4q+FOHqXIWJQ9rweNcm7DuRypSIaPbGpRodS0RERESKQUVfbspsMtEjpAGTR7TDqaod7y/fw+Ifj3I9J8/oaCIiIiJyB1T05U81qO3ElJHt6NbOiw27kghfsINTybpBh4iIiIi1U9GX27KzteGJh5oy8fE2ZGbn8sainXy37VSZ3/VXRERERO6cir7cMf9GrswYE0qbJrVY/nMcs5bGknrlmtGxREREROQmVPSlWByr2vFc/5aM6tWc+OSrTJkfzfaD54yOJSIiIiJ/oKIvxWYymbgvoB7ho4Kp51aN//vmAHPWHCDzWo7R0URERETk/1PRl7vm4VKNScMC6depEdEHzzN1fjRHEi4ZHUtEREREUNGXe2RjNtOnUyNeHRaIjdnMO0tiWfFzHLl5FqOjiYiIiFRqKvpSIhp71mDa6GA6BdRl3bZTvLkohrOpGUbHEhEREam0VPSlxFSxt2VULz8m9G9Fato1wiN3sGlXEvn5WoZTREREpKzZGh1AKp4gX3d86jkzf90hPvvxKHviUhnVy48a1e2NjiYiIiJSaeiMvpQKFycHXhzcmiceasrBk5eYErGd3ccuGB1LREREpNJQ0ZdSYzaZ6NbOi6kj21HT0YEPv9rLou8Pk309z+hoIiIiIhWeir6UOk93RyaPaMfDIQ3YvPsM0xbsIP5smtGxRERERCo0FX0pE3a2ZgZ3bcLLQ9pwPSePtz6LYe3Wk1gsulBXREREpDSo6EuZ8mvoyvQxIQQ2c2flLyd4e8kuLlzOMjqWiIiISIWjoi9lrnoVO57p68/Y3n4knk9nyvxotu4/q2U4RUREREqQir4YwmQy0aFlXaaPDsHLw5F5aw/x6eoDZFzLMTqaiIiISIWgoi+GqlWzKn9/MpAB9/uw62gKUyKiOXTyotGxRERERMo9FX0xnNlsoneHhrw2PAh7OxtmLd3Nso3Hycm1GB1NREREpNxS0Rer0aiuM9NGBtO5rSffRyfwxqKdnE5JNzqWiIiISLmkoi9WxcHehhE9fPnLwAAup2cTvmAnP+1MxKILdUVERESKRUVfrFKbprWYPiaUFg1d+GL9Md5ftofL6dlGxxIREREpN1T0xWrVqG7PXx8LYHj3ZhxNvMyUiGhijqQYHUtERESkXFDRF6tmMpl4ILA+U0cF4+ZchY9X7SNy3SGuXc81OpqIiIiIVVPRl3Khrlt1/jEiiEfae7Nl71mmzd9B3JkrRscSERERsVoq+lJu2NqYGdi5Ma882ZY8i4WZn+3imy3x5Fm0DKeIiIjIH6noS7nj28CF8NEhhLTw4Ost8fzz812cv5RpdCwRERERq6KiL+VStSp2jHvUn3F9WnAmNZOpkTv4de8Z8rUMp4iIiAigoi/lXFiLOkwfHUKjOk5ErjvM7FX7Sc/KMTqWiIiIiOFU9KXcc6tRhZeHtGVQl8bsPn6B1yO2cyD+otGxRERERAyloi8VgtlsomeYN5NHtKOagy3vfbmbL9YfIyc3z+hoIiIiIoZQ0ZcKxbuOE1NGBvNgYH1+2pnI9IU7STyfbnQsERERkTKnoi8VjoOdDUO7N+OFQa25mpnDjIU7+CE6AYsu1BUREZFKREVfKqyAxm5MHxNCKx83vtx4nPeW7uZi2jWjY4mIiIiUCRV9qdCcq9nz/IBWPPWwL3FnrjB1fjQ7Dp83OpaIiIhIqVPRlwrPZDLRuY0n4aNC8HCpyidf7ydi7UGysnONjiYiIiJSalT0pdKo7VqNV4cF8WiHhmw9kMzU+dEcS7psdCwRERGRUqGiL5WKrY2Z/vf7MGloIAD/XLyLlb+cIDfPYnAyERERkZKloi+VUtP6NQkfHUIH/zqs3XqSmZ/HkHwx0+hYIiIiIiVGRV8qraoOtozp3YJn+7Xk/KUspkVG8/Pu0+RrGU4RERGpAFT0pdILbu7B9DGhNK5Xg0XfH+Gjr/aRlnnd6FgiIiIi98TWyDc/f/48ixYtYs+ePezfv5/MzEwWLVpEaGjobV87adIkVq1aVWR769atWbZsWZHt8fHxfPDBB2zbto3MzEw8PT0ZMGAATz/9NABZWVmsXLmS9evXc+zYMTIyMmjYsCGDBw9m8ODB2NjY3PsHFqvl4uTAxCFtWL8jkRWb45gSEc3oXn4ENHYzOpqIiIjIXTG06MfHxzN37ly8vb3x9fUlNja2WK+vWrUq4eHhhba5uroW2e/AgQOMGDECHx8fxo8fT/Xq1UlMTCQ5Oblgn8TERGbMmEH79u0ZOXIkjo6ObNmyhWnTprFv3z7eeuutu/uQUm6YTSa6hzTAr6Erc9Yc4P3le3gwsD6DHmiMvZ1+0RMREZHyxdCi7+/vz7Zt23BxcWH9+vVMmDChWK+3tbWlb9++f7pPXl4er7zyCu3bt+fDDz/EbL75bKVatWqxZs0amjZtWrBtyJAhvPrqq3z11Vc8++yzeHl5FSuflE9eHo5MeaodK34+wU87Ezl46iLjHvXHu46T0dFERERE7pihc/QdHR1xcXG5p2Pk5eWRnp5+y+e3bNnC8ePHefHFFzGbzWRkZGCxFF1K0dXVtVDJv6Fbt24AnDhx4p5ySvliZ2vDEw81ZeLjbcjKzuWNRTtZt+0UFosu1BUREZHyoVxfjJuRkUFQUBBBQUGEhoYyc+ZMsrOzC+0TFRWFo6Mj586do0ePHgQGBhIYGMjkyZPJysq67XtcuHAB4J5/IZHyyb+RK9PHhNKmaS1W/BzHu1/EknrlmtGxRERERG7L0Kk798Ld3Z2xY8fi5+eHxWJh06ZNLFiwgLi4OObNm1ew36lTp8jLy+O5555j4MCBTJw4kdjYWCIjI7l48SKzZ8++5Xtcv36dhQsX0qBBA1q2bFkWH0uskGNVO57r15Lf9iWzeP1RpsyPZniPZoS1qGN0NBEREZFbKrdFf+LEiYUe9+7dm9q1axMREcFvv/1Gx44dAcjMzCQrK4shQ4bw+uuvA9C9e3dMJhMREREcPnyY5s2b3/Q9ZsyYQVxcHHPnzr3l3P4/4+bmWOzXlAR3d80lLw39H3QmrLUn/1oSw5xvDnI0KY3xAwJwrGp3R6/XuFgfjYl10rhYH42JddK4WB9rG5NyW/RvZvTo0URERBAVFVVQ9KtUqQL8/ovAf+vTpw8RERHExMTctOjPmzePZcuWMXHiRO677767ypOaml7mc7rd3Z1ISblapu9ZmdgCEx9vzbdbT/HNbyfZdzyFsb1b4Nvgz6d2aVysj8bEOmlcrI/GxDppXKyPEWNiNpv+9MRyuZ6j/0e1atXCzs6OK1euFGxzd3cHwM2t8HroNx6npaUVOc7KlSuZNWsWQ4cOZdy4caWYWMojG7OZPp0a8eqwQGzMZt5ZEsuKn+PIzSt6kbeIiIiIUSpU0U9OTiYnJ6fQWvr+/v4AnDt3rsi+UHTd/fXr1zN58mS6d+/O5MmTSzmxlGeNPWswbXQw97Wuy7ptp3hzUQxnUzOMjiUiIiIClJOin5CQQEJCQsHj7Ozsmy6peePC2k6dOhVs69q1K3Z2dqxYsaLQvsuXL8dkMhEWFlawbceOHbz00ku0a9eOWbNm3dW8fKlcqtjbMrKnH88PaEVq2jXCI3ewcVcS+flahlNERESMZfgc/RvlPC4uDoDVq1cTExODs7Mzw4YNA2DkyJEAbNy4EYCUlBT69+9P79698fHxKVh1Jyoqil69ehEcHFxw/Nq1azNu3Dg+/vhjcnJyCAsLIzY2lm+++YYnn3wSb29vAE6fPs2zzz6LyWSiR48efPfdd4VyBgYG6oZZckuBzdzxqefM/G8P8fmPR9kbl8qoXn7UqG5vdDQRERGppEz5Bp969PX1vel2T0/PgmLftWtX4D9FPy0tjRkzZrBnzx7Onz+PxWKhYcOG9O/fnxEjRmBjY1PoWPn5+SxcuJAlS5Zw5swZPDw8GDRoEOPHjy84a799+3ZGjBhxy5wzZ85kwIABxfpsuhi38rHk57MxJollm+Ko6mDDqJ5+tGlaS+NihTQm1knjYn00JtZJ42J9rPFiXMOLfkWmol95nU5JZ86agySeT6dLm3pMGNyWq2m3v0GblB19r1gnjYv10ZhYJ42L9bHGoq9J6CKlwNPdkckj2vFwaAM27z7DC//+mfizRVd4EhERESktKvoipcTO1szgB5rw8hNtyb6ex1ufxbBm68ky/yuPiIiIVE4q+iKlzM/bhY9efoAgX3dW/XKCfy7ZRcplTeMRERGR0qWiL1IGHKvZM76PP0/3bsHplHSmzo9m6/6zWoZTRERESo2KvkgZMZlMtG9Zh/BRIXh5ODJv7SE+XX2AjGs5RkcTERGRCkhFX6SM1apZlb8/GciA+33YdTSFKRHRHDp50ehYIiIiUsGo6IsYwGw20btDQ14bHoS9nQ3vLt3NlxuPkZNrMTqaiIiIVBAq+iIGalTXmWkjg+nS1pMfohOZsXAnp1PSjY4lIiIiFYCKvojBHOxtGNHDl788FsCVjGzCF+zkp52JWHShroiIiNwDFX0RK9GmSS2mjwmlRUMXvlh/jPeX7eFyerbRsURERKScUtEXsSI1qtvz18cCGN69GUcTLzMlIpqYIylGxxIREZFySEVfxMqYTCYeCKzP1FHBuDlX4eNV+4hcd4hr13ONjiYiIiLliIq+iJWq61adf4wI4pH23mzZe5Zp83cQd/qK0bFERESknFDRF7FitjZmBnZuzN+HBpJnyWfm57tYvSWePIuW4RQREZE/p6IvUg4086pJ+OgQQlt4sHpLPP/8fBfnL2UaHUtERESsmIq+SDlRrYotTz/qz/g+/pxJzWRq5A5+3XuGfC3DKSIiIjehoi9SzoS2qM300SE0quNE5LrDzF61n/SsHKNjiYiIiJVR0Rcph9xqVOHlIW0Z9EBjdh+/wOsR29kfn2p0LBEREbEiKvoi5ZTZbKJnqDevP9WOag62/OvLPSxZf5Sc3Dyjo4mIiIgVUNEXKeca1HZi6shgHgyqz/qdSUxfsJPE8+lGxxIRERGDqeiLVAD2djYM7daMFwa15mpWDjMW7uCH6AQsulBXRESk0lLRF6lAAhq7MX1MCK183Phy43HeW7qbi2nXjI4lIiIiBlDRF6lgnKvZ8/yAVozs2Zy4M1eYOj+aHYfPGx1LREREypiKvkgFZDKZuL91PcJHheDhUo1Pvt7PvLUHycrONTqaiIiIlBEVfZEKrLZrNV4dFsijHRoSdSCZqfOjOZZ02ehYIiIiUgZU9EUqOFsbM/3v9+HVoUEA/HPxLlb+coLcPIvByURERKQ0qeiLVBJN6tcgfHQIHVrWYe3Wk8z8PIbki5lGxxIREZFSoqIvUolUdbBlzCMteK5fS85fymJaZDQ/7z5NvpbhFBERqXBU9EUqoXbNPZg+JpQmnjVY9P0RPvpqH2mZ142OJSIiIiVIRV+kknJxcuClx9swpGsT9senMiUimr1xF4yOJSIiIiVERV+kEjObTHQPacCUp4JxqmbH+8v38vmPR8jOyTM6moiIiNwjFX0Rob6HI1Oeakf3YC827jrN9AU7OJV81ehYIiIicg9U9EUEADtbG4Y82JSJj7chKzuXNxbtZDXmgBEAACAASURBVN22U1gsulBXRESkPFLRF5FC/Bu5Mn1MKG2a1mLFz3G8+0UsqVeuGR1LREREiklFX0SKcKxqx3P9WjK6lx8nz11lyvxoth1INjqWiIiIFIOKvojclMlkolNAXcJHh1CvVjXmrDnInG8OkHktx+hoIiIicgdU9EXkT3nUrMqkoYH0u68R0YfOM3V+NEcSLhkdS0RERG5DRV9EbsvGbKZPx0a8OjwQGxsz7yyJZcXPceTmWYyOJiIiIregoi8id6xxvRpMGxXMfa3rsm7bKd5cFMPZ1AyjY4mIiMhNqOiLSLFUsbdlZE8/nh/QitS0a4RH7mDjriTy87UMp4iIiDWxNTqAiJRPgc3c8annzPx1h/j8x6PsjUtlVC8/alS3NzqaiIiIoDP6InIPajo68OKg1gzt1oxDpy4xJWI7u49dMDqWiIiIoKIvIvfIZDLxYFB9pjzVjpqODnz41V4WfX+Y7Ot5RkcTERGp1FT0RaREeLo7MnlEOx4ObcDm3WeYtmAH8WfTjI4lIiJSaanoi0iJsbM1M/iBJrz8RFuu5+Tx1mcxrNl6EotFF+qKiIiUNRV9ESlxft4uTB8TQpCvO6t+OcE/l+wi5XKW0bFEREQqFRV9ESkV1avYMb6PP08/2oLTKelMnR/Nb/vOahlOERGRMqKiLyKlxmQy0d6/DuGjQmjg4UjEt4f4dPUB0rNyjI4mIiJS4anoi0ipq1WzKq88GcjAzj7sOprC1PnRHDp50ehYIiIiFZqhRf/8+fPMmjWL4cOH07ZtW3x9fdm+ffsdvXbSpEn4+voW+Td48OCb7h8fH88LL7xAWFgYAQEB9OzZk7lz5xbZb9euXTzxxBO0bt2ajh078sYbb5CVpbnFIvfKbDbxSPuGvDY8CHs7G95dupsvNx4jJ9didDQREZEKydA748bHxzN37ly8vb3x9fUlNja2WK+vWrUq4eHhhba5uroW2e/AgQOMGDECHx8fxo8fT/Xq1UlMTCQ5ObnQfocOHWLkyJE0adKESZMmkZyczPz580lKSuLTTz8t/gcUkSIa1XVm2shglm06zg/RiRyIv8S4Pi2o7+5odDQREZEKxdCi7+/vz7Zt23BxcWH9+vVMmDChWK+3tbWlb9++f7pPXl4er7zyCu3bt+fDDz/EbL71HzH+9a9/UbNmTT777DOqV68OQP369Zk8eTJRUVG0b9++WPlE5OYc7G0Y3sOXVo3diFx3iOkLdjKoS2MebFcfs8lkdDwREZEKwdCpO46Ojri4uNzTMfLy8khPT7/l81u2bOH48eO8+OKLmM1mMjIysFiKThVIT09n69at9OvXr6DkA/Tt25dq1arx3Xff3VNOESmqTZNaTB8TSouGLnyx4Rj/XraHS1ezjY4lIiJSIZTri3EzMjIICgoiKCiI0NBQZs6cSXZ24ZIQFRWFo6Mj586do0ePHgQGBhIYGMjkyZMLzb0/cuQIubm5tGzZstDr7e3t8fPz49ChQ2XymUQqmxrV7fnrYwEM7+HLscTLTJ0fTcyRFKNjiYiIlHuGTt25F+7u7owdOxY/Pz8sFgubNm1iwYIFxMXFMW/evIL9Tp06RV5eHs899xwDBw5k4sSJxMbGEhkZycWLF5k9ezYAKSkpBce92Xvt3r27bD6YSCVkMpl4oK0nzRvUZM43B/l41T46BdTlyYeaUsW+3P6YEhERMVS5/R904sSJhR737t2b2rVrExERwW+//UbHjh0ByMzMJCsriyFDhvD6668D0L17d0wmExERERw+fJjmzZtz7do14Pcz+H/k4OBQ8HxxuLkZc3Ghu7uTIe8rf07jcnvu7k78u4kHX/x4mBUbjxF3Oo2XhgbS3LvoRfYl9X5ifTQu1kdjYp00LtbH2sak3Bb9mxk9ejQRERFERUUVFP0qVaoAv/8i8N/69OlDREQEMTExNG/evGC/69evFzludnZ2wfPFkZqajsVStncBdXd3IiXlapm+p9yexqV4egZ70biOE3PXHOTvH23h0Y4N6d3BG5s/uZi+uDQm1knjYn00JtZJ42J9jBgTs9n0pyeWy/Uc/T+qVasWdnZ2XLlypWDbjak4bm5uhfa98TgtLa3Qfjem8Py3lJQUPDw8SiWziNxcM6+ahI8OIbSFB6u3xDPz812cu5RpdCwREZFyo0IV/eTkZHJycgqtpe/v7w/AuXPniuwL/1l3v1mzZtja2rJ///5C+12/fp1Dhw7h5+dXmtFF5CaqVbHl6Uf9Gd/Hn+TUTKbN38Gve86Qn1+2fykTEREpj8pF0U9ISCAhIaHgcXZ29k2X1LxxYW2nTp0KtnXt2hU7OztWrFhRaN/ly5djMpkICwsDwMnJifbt27N69WoyMjIK9lu9ejWZmZk8/PDDJfqZROTOhbaozfQxITSq60Tkd4eZvWo/6Vk5RscSERGxaobP0b9RzuPi4oDfi3VMTAzOzs4MGzYMgJEjRwKwceNG4PepNP3796d37974+PgUrLoTFRVFr169CA4OLjh+7dq1GTduHB9//DE5OTmEhYURGxvLN998w5NPPom3t3fBvi+++CJDhgxh+PDhDBo0iOTkZCIjI7n//vvp0KFDWXw5ROQWXJ2r8PITbfkhOoGVm09wPGI7Yx7xo2Ujt9u/WEREpBIy5ZfA38Bzc3PZsGEDV65c4YEHHrjpEpW34uvre9Ptnp6eBcW+a9euwH+KflpaGjNmzGDPnj2cP38ei8VCw4YN6d+/PyNGjMDGxqbQsfLz81m4cCFLlizhzJkzeHh4MGjQIMaPH1/kTrk7d+5k1qxZHDx4EEdHR3r16sVLL71EtWrV7vgz3aCLceUGjUvJSjh3lTlrDnLmQgYPtavPoC6NsbO1uf0L/4vGxDppXKyPxsQ6aVysjzVejFvsov/OO++wfft2vvrqK+D3Ej1ixAh27txJfn4+NWvWZNmyZTRo0ODeklcAKvpyg8al5F3PyWP5z3FsiEnCs1Z1nn60BQ1q3/myZhoT66RxsT4aE+ukcbE+1lj0iz1H/9dff6Vdu3YFjzdu3MiOHTsYM2YM7733HgBz5sy5i6giInfO3s6God2a8eLg1qRn5fDGop18vz0Biy7UFRERAe5ijn5ycnKhee2bNm2ifv36vPzyywAcO3aMNWvWlFxCEZE/0crHjfAxISz87jDLNh1n34lUxjzih6tz8e99ISIiUpEU+4x+Tk4Otrb/+f1g+/bthS5U9fLyuula9CIipcW5mj3PD2jFyJ7NiTtzhanzo9lx+LzRsURERAxV7KJfp04dYmNjgd/P3icmJhZa5SY1NfWuLlwVEbkXJpOJ+1vXI3xUCB4u1fjk6/3MW3uQrOxco6OJiIgYothTdx555BFmz57NxYsXOXbsGI6OjnTu3Lng+UOHDulCXBExTG3Xarw6LJC1W0+yZutJjiZeZmzvFjTzqml0NBERkTJV7DP648ePp3///uzevRuTycTbb7+Ns7MzAFevXmXjxo20b9++xIOKiNwpWxsz/e7z4dVhQZhM8PaSXaz8JY7cPIvR0URERMpMiayjf4PFYiEjI4MqVapgZ2dXUoctt7S8ptygcTFOVnYuX6w/xpZ9Z2lYx4lgPw82xiRxMS0bV2cHBnRuTHv/OkbHlP9P3yvWR2NinTQu1scal9cs0Tvj5ubm4uR05+tYi4iUtqoOtox+xI+Axm7MW3uA5Zv+80M4NS2bhd8dBlDZFxGRCqfYU3c2b97MRx99VGjb4sWLCQwMpE2bNkycOJGcnJwSCygiUhLaNfegehX7Ituv51pYuTnOgEQiIiKlq9hFPyIighMnThQ8jouL46233sLDw4MOHTqwbt06Fi9eXKIhRURKwqX07JtuT027+XYREZHyrNhF/8SJE7Rs2bLg8bp163BwcGDFihXMmzePXr168fXXX5doSBGRkuDm7HDT7dWq2FKClyuJiIhYhWIX/StXruDi4lLweOvWrYSFheHo+PuFACEhISQlJZVcQhGREjKgc2PsbQv/2DOZIPNaLrO/3k/mNa25LyIiFUexi76LiwtnzpwBID09nX379tGuXbuC53Nzc8nLyyu5hCIiJaS9fx2e6tkcN2cHTPx+hn/MI34MfqAJsUcvMH3BDk4laxULERGpGIq96k6bNm1YunQpTZo04ZdffiEvL4/777+/4PlTp07h4eFRoiFFREpKe/86tPevU2QZtMaezny6+gBvfhbDEw81pUubephMJgOTioiI3Jtin9H/y1/+gsVi4YUXXmDlypX069ePJk2aAJCfn8/69esJDAws8aAiIqWpaf2aTB0VTPMGNfnshyPMWXOQrGxN5RERkfKr2Gf0mzRpwrp169i1axdOTk4EBwcXPJeWlsZTTz1FaGhoiYYUESkLztXseWFwa9ZFnWLVryc4mXyVCf1aUt/j1jcjERERsVYlemdcKUx3xpUbNC7W53ZjcvjUJf7vmwNkZecytHsz7guoV4bpKi99r1gfjYl10rhYnwp1Z9yEhAQ2bNhAYmIiAF5eXjz44IM0aNDgbg8pImI1mnu7MG10CHO+OUDkusMcTbjMsO6+ONjbGB1NRETkjtxV0X///feZO3dukdV13n33XcaPH89f//rXEgknImKkGtXtmfh4G775LZ41v53kZPJVnu3Xknq1qhsdTURE5LaKXfRXrFjBp59+Stu2bRk7dixNmzYF4NixY0RERPDpp5/i5eXFgAEDSjysiEhZM5tN9LvPh6b1azJnzQFmLNzJiId9ae9fx+hoIiIif6rYc/QHDBiAnZ0dixcvxta28O8Jubm5DB06lJycHFauXFmiQcsjzdGXGzQu1uduxuTS1Wz+b/V+jiZdoXObejz5UFPsbDWVpyTpe8X6aEysk8bF+ljjHP1iL68ZFxdHr169ipR8AFtbW3r16kVcXFxxDysiYvVcnBz425Nt6RXmzebdZ3hzUQznLmUaHUtEROSmil307ezsyMy89X9sGRkZ2NnZ3VMoERFrZWM281iXxvz1sQBS064RHrmDHYfPGx1LRESkiGIX/VatWvHll19y4cKFIs+lpqaybNkyWrduXSLhRESsVesmtZg2KgTPWtX55Ov9LP7xKDm5FqNjiYiIFCj2xbjPPfccI0eOpFevXgwcOLDgrrjHjx9n5cqVZGRkMGvWrBIPKiJibdxqVOHvQwNZ8XMcP+5IJO7MFZ7t1xL3mlWNjiYiInJ3N8zauHEjM2bM4OzZs4W216tXjylTptClS5eSyleu6WJcuUHjYn1KekxijqQwf90hTMCYR/xo28y9xI5dmeh7xfpoTKyTxsX6WOPFuHe1jn7Xrl3p0qUL+/fvJykpCfj9hln+/v4sW7aMXr16sW7durtLLCJSDgX5uuNV25FPVu3no5X76BHixcDOjbG1KfYMSRERkRJx13fGNZvNBAQEEBAQUGj7pUuXiI+Pv+dgIiLljUfNqrw2PJClG4/zQ3Qix09f4dm+LXF1rmJ0NBERqYR0qklEpATZ2dowvLsvz/T1Jyklg2mRO9gbl2p0LBERqYRU9EVESkGIX22mjgympqMD7y/fw1eb48izaFUeEREpOyr6IiKlpI5rNSaPCOL+1nX5NuoUs77YzaWr2UbHEhGRSkJFX0SkFNnb2TCypx9jHvEjPjmN8MhoDp68aHQsERGpBO7oYtzIyMg7PuCuXbvuOoyISEXVsVVdGtZ1Zvaqfby3dDd9OjXi0Q4NMZtNRkcTEZEK6o6K/ttvv12sg5pM+o9LROSPPGtVZ8pTwSz64Qirt8RzLOky4x71x7m6vdHRRESkArqjor9o0aLSziEiUik42Nswtrcfvg1qsvino0yNjOaZPv74NnAxOpqIiFQwd1T0Q0JCSjuHiEilYTKZuL91PRrWceKTr/fzzhexDLjfh55h3pj1F1ERESkhuhhXRMQgDWo7MWVkMMHNPfhq8wk+XLGX9Kwco2OJiEgFoaIvImKgqg62jO/jz7DuzTh48iLTIqM5fvqK0bFERKQCUNEXETGYyWSia2B9XhsehNlk4u3Fu/gxOoH8/Hyjo4mISDmmoi8iYiUa1nFm2qhgAhq7sXTjcf535T4yrmkqj4iI3B0VfRERK1Ktih3PD2jFkAebsjculfDIHcSfTTM6loiIlEMq+iIiVsZkMtE92ItJQwOx5Ocz8/MYNsQkaSqPiIgUi4q+iIiVauxZg2mjQmjR0JXFPx3l09UHyMrONTqWiIiUEyr6IiJWzLGqHX95LIDHujQm5kgK0xfsIOHcVaNjiYhIOaCiLyJi5cwmE73CvHnlybZk5+TxxqIYNu8+rak8IiLyp1T0RUTKiWZeNZk2KgRfrxos/P4I89Ye5Np1TeUREZGbU9EXESlHnKvb8+LgNvS7rxHbDpxjxsKdnE5JNzqWiIhYIRV9EZFyxmw20adjIyYOaUNGVg4zFu3kt31njY4lIiJWRkVfRKScatHQlWmjQ2hUx5mIbw8Rue4Q13PyjI4lIiJWwtbINz9//jyLFi1iz5497N+/n8zMTBYtWkRoaOhtXztp0iRWrVpVZHvr1q1ZtmxZweOkpCQefPDBmx5j7ty53H///YW2rVu3jsjISE6cOIGdnR3NmjXjmWeeoUOHDsX8dCIipa+mowMvP9GG1VviWbv1FPFn03i2X0vqulU3OpqIiBjM0KIfHx/P3Llz8fb2xtfXl9jY2GK9vmrVqoSHhxfa5urqetN9+/TpQ6dOnQpta968eaHHixcvZvr06XTp0oUBAwaQnZ3NV199xejRo4mIiKBjx47FyiciUhZszGYG3N+YpvVrMnfNQaYv3MnIh5sT2qK20dFERMRAhhZ9f39/tm3bhouLC+vXr2fChAnFer2trS19+/a94/e63b6ff/45rVq14tNPP8VkMgHQr18/OnXqxDfffKOiLyJWrZWPG9NGBfPp6gP83zcHOJp4mSEPNsHO1sboaCIiYgBD5+g7Ojri4uJyT8fIy8sjPf3OVpzIzMzk+vXrt3w+PT0dNze3gpIP4OzsjIODAw4ODveUU0SkLLg6V+GVJ9vycEgDNsWe5q3PdnH+UqbRsURExADl+mLcjIwMgoKCCAoKIjQ0lJkzZ5KdnX3TfT/44APatm1LQEAAjz/+ODt27CiyT0hICL/++iufffYZSUlJxMXFMWXKFPLz8xk6dGhpfxwRkRJha2NmcNcm/M/AVqRcziJ8wQ5ijpw3OpaIiJQxQ6fu3At3d3fGjh2Ln58fFouFTZs2sWDBAuLi4pg3b17BfmazmU6dOtGtWzc8PDw4deoUERERjBo1igULFtCuXbuCfV977TVSU1N54403eOONNwCoVasWixYtwtfXt8w/o4jIvWjb1J1poxz5ZPV+Pl61n27tvBj0QGNsbcr1OR4REblDpnwruYf6jTn6d7rqzs288847REREMH/+/D+dT3/u3DkeeeQRmjRpwtKlSwu2Z2ZmMmvWLLKysujcuTMZGRksWLCAy5cvs2TJEry8vO4ql4iIkXJyLUSuPcCaX0/g28CFV4a3w8O1mtGxRESklJXbM/o3c2N1nKioqD8t+rVr1+aRRx5h2bJlZGVlUbVqVQD+8pe/4ODgwMcff1yw74MPPkiPHj14//33ee+994qVJzU1HYulbH+Pcnd3IiXlapm+p9yexsX6VLYx6d+xIV5u1Zi/7hB/eW8TY3q3oE2TWkbHKqKyjUt5oDGxThoX62PEmJjNJtzcHG/9fBlmKXW1atXCzs6OK1eu3HbfunXrYrFYSEtLAyAxMZFff/2Vrl27FtqvZs2aBAYGFnvpTxERa9OuuQdTRwXj5lyFD1fsZfmm4+TmWYyOJSIipaRCFf3k5GRycnJuuZb+f0tMTMTGxoYaNWoAcOHCBQAslqL/6eXm5pKbm1uyYUVEDFDbpRr/GBFElzb1+G57Au9+EculqzdfxEBERMq3clH0ExISSEhIKHicnZ190yU1Z8+eDVDoxlgXL14sst+pU6f49ttvadeuHVWqVAHA29sbs9nMunXrCu2bnJzMzp07adGiRYl8FhERo9nZ2jDi4eaMe7QFCefSmTo/mv3xqUbHEhGREmb4HP0b5TwuLg6A1atXExMTg7OzM8OGDQNg5MiRAGzcuBGAlJQU+vfvT+/evfHx8SlYdScqKopevXoRHBxccPx3332XxMREwsLC8PDwICEhoeAC3L///e8F+7m6ujJw4ECWL1/OU089Rffu3UlPT2fJkiVcv36dp59+utS/FiIiZSnMvw7edZyYvWo///5yD707NKRvp0aYzabbv1hERKye4avu3GrZSk9Pz4Jif2Pe/I3HaWlpzJgxgz179nD+/HksFgsNGzakf//+jBgxAhub/9wFcu3atSxdupTjx49z9epVnJ2dCQkJ4fnnn6dp06aF3jM3N5elS5eyYsUKTp06BUBAQAATJkwgJCSk2J9NF+PKDRoX66Mx+Y/snDwW/3iULfvO0rxBTcb38aeGozE3CdS4WB+NiXXSuFgfa7wY1/CiX5Gp6MsNGhfrozEp6te9Z1j841GqONgyvo8/ft73dufyu6FxsT4aE+ukcbE+1lj0y8UcfRERKX33BdRj8lPtqOZgy6ylsazZehKLzgWJiJRbKvoiIlKgvrsjU0a2I9SvNqt+OcH7y/aQlnnd6FgiInIXVPRFRKSQKva2PP1oC0b08OVwwmXCI3dwLOmy0bFERKSYVPRFRKQIk8lEl7ae/GN4EHY2Zt5eHMt3209pKo+ISDmioi8iIrfkXceJKSODadusFss3xfG/X+0jPSvH6FgiInIHVPRFRORPVatiy3P9WvLkQ03ZdyKV8MgdxJ25YnQsERG5DRV9ERG5LZPJxEPtvHh1WBAA//x8Fz/tTEQrNIuIWC8VfRERuWM+9ZyZOiqYVj5ufLH+GLO/3k/mtVyjY4mIyE2o6IuISLE4VrXjfwa2YvADTYg9eoHwBdGcStaNe0RErI2KvoiIFJvJZOLh0Ab8fWhbcvPyefOzGDbFntZUHhERK6KiLyIid61p/ZpMGxVMc++afPbDEeasOUhWtqbyiIhYAxV9ERG5J07V7HlhUGsG3O9D9KFzTF+4k6Tz6UbHEhGp9FT0RUTknplNJnp3aMjfhrTlWnYubyzaya97zxgdS0SkUlPRFxGREtPc24Vpo0No7FmDyHWHiVh7kOzreUbHEhGplFT0RUSkRNWobs/Ex9vQp2NDtu5P5o1FOzlzIcPoWCIilY6KvoiIlDiz2US/+3x46fE2pGVeZ8bCnUQdSDY6lohIpaKiLyIipca/kSvTRoXgXduRuWsOsvD7w1zP0VQeEZGyoKIvIiKlysXJgb892ZZeYd5s3n2GNz+L4dzFTKNjiYhUeCr6IiJS6mzMZh7r0pi/PhbAxbRrhC/YwY7D542OJSJSoanoi4hImWndpBbTRoXgWas6n3y9n8U/HiUn12J0LBGRCklFX0REypRbjSr8fWgg3YO92LAriZmfx5ByOcvoWCIiFY6KvoiIlDlbGzNDHmzKhP6tOHcpi/DIHcQeTTE6lohIhWJrdAAREam8gnzd8artyCer9vPRyn0kpmbSK8QLWxudhxIRuVf6SSoiIobyqFmV14YH8kCgJ19vjuPtJbu4mHbN6FgiIuWeir6IiBjOztaG4d19eWVYO5JSMpgWuYO9calGxxIRKddU9EVExGrc19aTqSODqenowPvL9/DV5jjyLFqVR0Tkbqjoi4iIVanjWo3JI4K4v3Vdvo06xbtf7ObS1WyjY4mIlDsq+iIiYnXs7WwY2dOPsb39OJmcRnhkNAdPXjQ6lohIuaKiLyIiVqtDy7q8/lQw1ava8d7S3azeEo/Fkm90LBGRckFFX0RErJpnrepMeSqYMP86rN4Sz7+W7SYt47rRsURErJ6KvoiIWD0HexvG9vZjZM/mHEu6wtTIaI4kXDI6loiIVVPRFxGRcsFkMnF/63r8Y3gQVexseOeLWL6NOoklX1N5RERuRkVfRETKlQa1nZgyMpjg5h58tfkEH67YS3pWjtGxRESsjoq+iIiUO1UdbBnfx59h3Ztx8ORFpkVGc/z0FaNjiYhYFRV9EREpl0wmE10D6/Pa8CDMJhNvL97FD9EJ5Gsqj4gIoKIvIiLlXMM6zkwbFUxAYze+3Hic/125j4xrmsojIqKiLyIi5V61KnY8P6AVQx5syt64VMIjdxB/Ns3oWCIihlLRFxGRCsFkMtE92ItJQwOx5Ocz8/MYNsQkaSqPiFRaKvoiIlKhNPaswbRRIbRo6Mrin47y6eoDZGXnGh1LRKTMqeiLiEiF41jVjr88FsBjXRoTcySF6Qt2kHDuqtGxRETKlIq+iIhUSGaTiV5h3rzyZFuyc/J4Y1EMm3ef1lQeEak0VPRFRKRCa+ZVk2mjQvD1qsHC748wb+1Brl3XVB4RqfhU9EVEpMJzrm7Pi4Pb0O++Rmw7cI4ZC3dyOiXd6FgiIqVKRV9ERCoFs9lEn46NmDikDRlZOcxYtJPf9p01OpaISKlR0RcRkUqlRUNXpo0OoVEdZyK+PcT8dYfIzskzOpaISIlT0RcRkUqnpqMDLz/Rht4dvNmy9yxvLtrJ2dQMo2OJiJQoFf3/1969B0RVp30A/84MA4zKDLcBSREE5SIoN5XAS+alCCmxLEsB03Q1dd/V2jK3ttQ27d3aNrNsTUikm6mJJJW35O2CeFcU8QaiQMpFiJvAgMx5/yBmHWEEgWGG4fv5h+Y3vzPzHB9O5+HMc35DREQ9kkQsxuNj3bH0KT+UVdVh1eZjOJxZaOiwiIg6DQt9IiLq0Ya62WHF7BFwVvbBhm/P4rM9F1B/i608RNT9sdAnIqIez1ZuiZdnBCBs5ACknPwNqz87gaLfqw0dFhFRh5gZ8s2LioqQkJCA9PR0ZGRkoLq6GgkJCQgODm5121deeQWJiYnNxv38/LB161bN4/z8fEyYMKHFXc9qxQAAHlFJREFU19i4cSPGjh2rNaZWq/Hll1/i66+/xtWrV9GrVy/4+PjgjTfewIABA+5xD4mIqLswk4jx1PhBGOysQFzyOayMP4o54d4I8nQwdGhERO1i0EI/JycHGzduhIuLCzw9PXHy5Ml72l4mk2HlypVaY7a2ti3OfeyxxzB69GitMS8vr2bzXn75Zezfvx/Tpk1DTEwMqqqqcPr0aZSVlbHQJyLqAQIGK7Fidh98nJSBjxIzMHF4fzz14CCYSfghOBF1LwYt9H18fHDo0CHY2Nhg//79WLRo0T1tb2ZmhilTprT5vVqbm5ycjN27d+OLL76An5/fPcVCRESmw95ahuVRQdh6IAv7j+Uj+7cKPB/pA3uFzNChERG1mUEvT/Tp0wc2NjYdeo2GhgZUVbXt2w2rq6tRV1en8/nNmzdj4sSJ8PPzw61bt1BTU9Oh2IiIqPsyk4gxY5IHFkb6oqD0JlZuOopTWTcMHRYRUZt1688hb968iaCgIAQFBSE4OBhr1qyBSqVqce7atWsREBCAYcOGYfr06Th69KjW81VVVThz5gw8PT3x+uuvIyAgAP7+/oiIiMCvv/7aFbtDRERGaLiXA15/dgTs5Jb4YPtpbEvJwq0GtaHDIiJqlUFbdzpCqVRi7ty58Pb2hlqtRkpKCuLj45GdnY3Y2FjNPLFYjNGjR2PSpElwcHDA1atXERcXh9mzZyM+Ph7Dhw8HAOTm5kIQBMTHx0OhUGDFihWQSCSIjY3F/Pnz8dVXX2HYsGGG2l0iIjIgR5teeDUmCF/tv4QfDuci67dyLJjiCxsrC0OHRkSkk0gQBMHQQQDQ9Oi3ddWdlvzzn/9EXFwcPv30U4waNUrnvMLCQkyePBmDBg3Cli1bAADHjh3DzJkzIZVKsW/fPjg5OQEASkpKMHHiRISGhuKjjz5qV1xERGQ6/u9EPj7adgrmUglenBmEQK7KQ0RGqtte0W/JnDlzEBcXh7S0tLsW+o6Ojpg8eTK2bt2KmpoayGQyWFg0XpUJDAzUFPkAYGdnh9DQUJw4ceKe4ykpqYJa3bV/RymVViguruzS96TWMS/GhzkxTt0hLz7OCvx91nCsT8zAik/SEBHqiimjB0IsFhk6NL3oDjnpiZgX42OInIjFItjZ9dH9fBfGonf29vaQSqUoLy9vda6TkxPUajUqKioAAA4ODprXuJOdnZ1mHhERkZNdb7w2azhGDXXCroNX8O6WkyivavkeMSIiQzGpQr+goAD19fU619K/XV5eHiQSCRQKBYDGq/z29vYoLCxsNrewsLDDqwMREZFpsZBKMGeyN2aHe+HytQq8sekozl393dBhERFpdItCPzc3F7m5uZrHKpWqxSU1169fDwBaX4xVWlrabN7Vq1fx3XffYfjw4bC0tNSMh4WF4eTJk8jOztaM5efnIzU1FaGhoZ2yL0REZFrGDLsPr80ajl4WZnh3y0nsSs2B2jhufyOiHs7gPfpNxXlTcZ2UlITjx49DLpcjKioKAPDss88CAA4cOAAAKC4uxtSpUxEREQE3NzfNqjtpaWkIDw/HiBEjNK//zjvvIC8vD/fffz8cHByQm5uruQF32bJlWrHMnz8fu3fvxqxZsxAdHQ2JRILPP/8cFhYW9/xlXkRE1HP0V/bB688OR8LuC0j8JQeX8ssx99EhkPcyN3RoRNSDGXzVHU9PzxbH+/Xrpynsx48fD+C/hX5FRQXefPNNpKeno6ioCGq1Gq6urpg6dSpiYmIgkUg0r5OcnIwtW7YgKysLlZWVkMvlGDlyJBYvXozBgwc3e98rV67g7bffxpEjRyAIAgIDA/Hyyy/rjPNueDMuNWFejA9zYpy6e14EQcBPp67hy/2XYNVLivmP+cDD2drQYXVId8+JqWJejI8x3oxr8ELflLHQpybMi/FhToyTqeTlakElPt6ZgRvltXhinBseHjkAYlH3XJXHVHJiapgX42OMhX636NEnIiLqTlz6WuH1Z0cgwMMe21Ky8eE3Z1BVU2/osIioh2GhT0REpAe9LM2wMNIXMyYOxpnLJVi56Siyr7W+/DMRUWdhoU9ERKQnIpEIE4c7Y3lUEADg7c9PYN+xPLBrloi6Agt9IiIiPXO7T443Zo/AUDc7fLX/EtbvzEB17S1Dh0VEJo6FPhERURfoI5Piz08MxVMPDsLJizewMv4IrhbwZkoi0h8W+kRERF1EJBIhLHgAls0MwK0GAW99dgwpJ39jKw8R6QULfSIioi42uL81VsweAS8XG3y25wI+2ZWJGhVbeYiocxn8m3GJiIh6Iqte5ljypB++T7uKxF8u40pBJRZF+qK/g+41sYnI+KSdLcCOn7JRWqGCrdwCjz/gjhCfvoYOCwCv6BMRERmMWCRCRKgrXno6ALWqW3gz4Rh+OX3N0GERURulnS3A5h/Oo6RCBQFASYUKm384j7SzBYYODQALfSIiIoPzcrHBijkjMaifApu+P4+45Eyo6hoMHRYR3UVdfQO2pmSh7pZae/yWGjt+yjZQVNrYukNERGQEFL3N8eJ0f3ybmoNdqVdwpaASz0f64j773oYOjahHalCr8XuFCsVlNSgur8WN8hrcKKtF8R8/y2/W6dy2pELVhZHqxkKfiIjISIjFIkSOccPg/tb4ZNdZvLn5GGLCPI2m35fIlAiCgIqbdY1FfFMxX1aDG+W1KC6rQWmFCurbVsQSiQBbK0sorS0x1M0OSmtL7DuWh6qa5jfS28ktunJXdGKhT0REZGR8BtpixeyR2JCUgY27MnExrwzPTBgMc6nE0KERdSvVtfUoLmu8Gt/0s6mQLymvbdZ2I+9tDqXCEu79FAgeYgmltQz2CkvYW8tga2UBM4l217u9tQybfziv9TrmZmI8/oB7l+xfa1joExERGSEbKwu8NCMAiT/n4PtDV3H5WgUWRvrC0baXoUMjMhr1txr+KNxva60pq9G011TfsWytzMIMSoUlnOx6/3FV/r+FvL3CEhb3+Md006dtxrrqDgt9IiIiIyURizFtnDsG91cgNjkTK+OPYna4N0Z4ORg6NKIuoemTv7295rZe+fIq7T55M4n4j8LdEu73KWBvbQmlQtZY0FtboreltNNjDPHpixCfvlAqrVBcbFzfds1Cn4iIyMj5DbLHitkj8Z+kDHy8MwMXA/vjqfGDIDXj4nnUvbXWJ/97pQoNah198gPtNIW8vbUl7BUyKPqYQywSGXCPjAsLfSIiom7ATmGJZTMDsf3/srH3aB6yr5Xj+UhfKK1lhg6N6K6qa29p98g3rVzzR1F/tz55e0XrffKkGwt9IiKibsJMIsbTEwZjcH9rfPr9OazcdBTPTfZGgIfS0KFRD9Zin/wfP2+U1+Bm7Z198hLYK2RwtJHBd6CtpohXKhqvyluY86bzzsJCn4iIqJsJ8lTC2bEPPk7MwLodZ/DwSGc88YA7r3SSXqjVAkora2+70bXtffJu98mbtdf0tjSDiO01XYKFPhERUTfkYC3D36IDseVAFvYcyUPWb+V4foovbOWWhg6NuhlBEFBRXf9Hj/x/r8Q3XaEvrWipT94C9orGK/JKaxn75I0UC30iIqJuSmomQfRDnvB0tsamH85jxaajmBsxBMPc7QwdGhmZu/bJl9egrv6OPvleUthbyzDQSY6R3jKt9hpbuSU/PeomWOgTERF1cyO9HTHA0QrrEzPw/rZ0TA5xQeSYgZCIWYz1FE198jduW72muIx98j0dC30iIiIT0Ne2F16LCcKX+y/iu7SruJRfjvmP+cDGysLQoVEn0OqTL69Bdb0audfKNctRljXrkxfBTtFYuA+8T95YwFvLoGSffI/CQp+IiMhEmEslePYRb3g4WyNhzwWs3HQEf3rMB0NcbQ0dGrXiXvvkxaLGb0+2V8jgM9BWq0deac0+eWrEQp+IiMjEhPo6waWvHOsTz+BfW07hsdED8WioK8RiFn6GVKO61dhO09KXQ7XQJ2/VSwqljj55Dzclyn6/aaA9oe6ChT4REZEJ6mffG6/PGoGEPReQ9GsOLuWXYd6jPlD0Njd0aCarpT7523/e2Sdvad7YJ+9gI8MQV9s7lqG0hKW57jKN34pMbcFCn4iIyERZmEswN8IbngOs8cW+i1ix6QgWPOYDzwE2hg6tW1KrBfxeqcKN8hoU3Xaja5v65J3+2yff9G2v7JMnfWOhT0REZMJEIhHG+t0H175W+HhnBv751Uk8PtYNj9zvwh7uOwiCgMrq+hZ75G+U1aKkolZ7PXkANvI/+uRdG9eTZ588GRMW+kRERD3AAEcrvP7sCGzefR7f/HQZl/LLMTdiCPrIpIYOrUvdrU/+RnktVPUNWvOteklhr5DB1ckKw70ctNpr7LiePBk5FvpEREQ9hMzCDPMf84GHszW2/HipsZVnii8G9VMYOrROU39LjZKK5j3yjWvKd26fPJGx428vERFRDyISiTA+sD/c7pNjfWIG/veLE5g2zh0PjXDuFv3it/fJF9/ZXlNei7JKFYTb5ptJRLCTN/bGD+xrpdUjzz55MnUs9ImIiHog175yrJg9AnHfncPXB7JwMa8McyZ7o7elYVt5OtInP8TFRquQt1dYwtrKgn3y1GOx0CciIuqhellKsfjxodh3LB/bUrKwctNRPB/pi4FOcr2+b43qls615G+UNe+T7yNrXE+effJE94aFPhERUQ8mEonw0AhnuN8nx8dJGVjz+XFMHz8YMgsJEn++jNIKFWzlFnj8AXeE+PRt02vq6pNvKuirauq15luYS6BUNBbv3i42miK+6Sf75Inah0cOERERwb2fAitmj0Rscia+2HcRYhHQ1CFTUqHC5h/OAwBCfPpCrRZQVqXSrF5z5yo2d+uTd72jT95eYYk+Min75In0gIU+ERERAWhskfmfacPwP+//gmqV9uo0dbfUiP/+PJJ+zUFJefM+eWsrCygVlvB2sdG62ZV98kSGw0KfiIiINMQiUbMiv0l9gxoujlYI8lRqtdfYyi0hNWOfPJGxYaFPREREWuzkFiipULU4/nykrwEiIqL24J/fREREpOXxB9xhfscVenMzMR5/wN1AERFRe/CKPhEREWlpWl1nx0/Z7Vp1h4iMAwt9IiIiaibEpy9CfPpCqbRCcXGlocMhonZg6w4RERERkQlioU9EREREZIJY6BMRERERmSAW+kREREREJoiFPhERERGRCWKhT0RERERkgljoExERERGZIBb6REREREQmiIU+EREREZEJ4jfj6pFYLOpR70t3x7wYH+bEODEvxoc5MU7Mi/Hp6py09n4iQRCELoqFiIiIiIi6CFt3iIiIiIhMEAt9IiIiIiITxEKfiIiIiMgEsdAnIiIiIjJBLPSJiIiIiEwQC30iIiIiIhPEQp+IiIiIyASx0CciIiIiMkEs9ImIiIiITBALfSIiIiIiE2Rm6ACodXV1dVi7di2SkpJQUVEBLy8vLF26FCEhIa1uW1hYiNWrVyM1NRVqtRr3338/li9fDmdn5y6I3LS1Ny/r1q3Dhx9+2Gzc3t4eqamp+gq3RygqKkJCQgLS09ORkZGB6upqJCQkIDg4uE3bZ2dnY/Xq1Thx4gSkUikefPBBLFu2DLa2tnqO3HR1JCevvPIKEhMTm437+flh69at+gi3Rzh9+jQSExNx+PBhXLt2DdbW1ggICMCSJUvg4uLS6vY8r+hHR/LC84p+nDlzBv/5z3+QmZmJkpISWFlZwcvLC4sWLUJgYGCr2xvDscJCvxt45ZVXsHfvXsTExMDFxQWJiYmYN28ePvvsMwQEBOjc7ubNm4iJicHNmzexYMECmJmZIT4+HjExMdi5cycUCkUX7oXpaW9emqxatQqWlpaax7f/N7VPTk4ONm7cCBcXF3h6euLkyZNt3ragoAAzZ86EXC7H0qVLUV1djU8//RQXL17E1q1bIZVK9Ri56epITgBAJpNh5cqVWmP8w6tjYmNjceLECYSFhcHT0xPFxcX44osvEBkZie3bt8Pd3V3ntjyv6E9H8tKE55XOlZeXh4aGBjz55JNQKpWorKzErl27EBUVhY0bN2LUqFE6tzWaY0Ugo5aeni54eHgImzZt0ozV1tYKEydOFGbMmHHXbT/55BPB09NTOHv2rGYsKytL8Pb2Ft5//319hdwjdCQvH3zwgeDh4SGUl5frOcqep7KyUigtLRUEQRD27dsneHh4CIcOHWrTtm+88Ybg7+8vFBQUaMZSU1MFDw8PYdu2bXqJtyfoSE6WLVsmBAUF6TO8Hun48eOCSqXSGsvJyRF8fX2FZcuW3XVbnlf0pyN54Xml61RXVwuhoaHCn/70p7vOM5ZjhT36Rm737t2QSqV48sknNWMWFhaYNm0ajh8/jqKiIp3b7tmzB/7+/hgyZIhmzN3dHSEhIfjhhx/0Grep60hemgiCgKqqKgiCoM9Qe5Q+ffrAxsamXdvu3bsX48ePh6Ojo2YsNDQUrq6uPF46oCM5adLQ0ICqqqpOiogCAwNhbm6uNebq6orBgwcjOzv7rtvyvKI/HclLE55X9E8mk8HW1hYVFRV3nWcsxwoLfSN37tw5DBw4EL1799YaHzZsGARBwLlz51rcTq1W48KFC/D19W323NChQ3HlyhXU1NToJeaeoL15ud24ceMQFBSEoKAgLF++HGVlZfoKl1pRWFiIkpKSFo+XYcOGtSmfpB83b97UHCfBwcFYs2YNVCqVocMyOYIg4MaNG3f9o4znla7XlrzcjucV/aiqqkJpaSkuX76M9957DxcvXrzr/XjGdKywR9/IFRcXa11hbKJUKgFA55XjsrIy1NXVaebdua0gCCguLsaAAQM6N+Aeor15AQC5XI7o6Gj4+flBKpXi0KFD+Prrr5GZmYlt27Y1u6JD+teUL13HS0lJCRoaGiCRSLo6tB5NqVRi7ty58Pb2hlqtRkpKCuLj45GdnY3Y2FhDh2dSvv32WxQWFmLp0qU65/C80vXakheA5xV9+9vf/oY9e/YAAKRSKZ5++mksWLBA53xjOlZY6Bu52traFm8CtLCwAACdV7aaxls6uJu2ra2t7awwe5z25gUAZs2apfU4LCwMgwcPxqpVq7Bz50489dRTnRsstaqtx8udn+CQfr344otajyMiIuDo6Ii4uDikpqbe9UY4arvs7GysWrUKQUFBmDJlis55PK90rbbmBeB5Rd8WLVqE6dOno6CgAElJSairq0N9fb3OP6CM6Vhh646Rs7S0RH19fbPxpl+ipl+YOzWN19XV6dyWd+O3X3vzosszzzwDmUyGtLS0TomP7g2Pl+5jzpw5AMBjpZMUFxdj/vz5UCgUWLt2LcRi3WUBj5Oucy950YXnlc7j6emJUaNG4YknnkBcXBzOnj2L5cuX65xvTMcKC30jp1QqW2wDKS4uBgA4ODi0uJ21tTXMzc018+7cViQStfiRErVNe/Oii1gshqOjI8rLyzslPro3TfnSdbzY2dmxbcdI2NvbQyqV8ljpBJWVlZg3bx4qKysRGxvb6jmB55Wuca950YXnFf2QSqWYMGEC9u7dq/OqvDEdKyz0jZyXlxdycnJw8+ZNrfH09HTN8y0Ri8Xw8PBARkZGs+dOnz4NFxcXyGSyzg+4h2hvXnSpr6/H9evXO7w6CbWPo6MjbG1tdR4v3t7eBoiKWlJQUID6+nqupd9BKpUKCxYswJUrV7Bhwwa4ubm1ug3PK/rXnrzowvOK/tTW1kIQhGY1QBNjOlZY6Bu5sLAw1NfXY9u2bZqxuro67NixA4GBgZobQq9du9Zs+a2HH34Yp06dQmZmpmbs8uXLOHToEMLCwrpmB0xUR/JSWlra7PXi4uKgUqkwZswY/QZOAIDc3Fzk5uZqjT300EM4cOAACgsLNWNpaWm4cuUKj5cucGdOVCpVi0tqrl+/HgAwevToLovN1DQ0NGDJkiU4deoU1q5dC39//xbn8bzStTqSF55X9KOlf9eqqirs2bMHTk5OsLOzA2Dcx4pI4GKrRu8vf/kLfvzxR8yaNQsDBgxAYmIiMjIysHnzZgQFBQEAoqOjceTIEVy4cEGzXVVVFaZOnYqamhrMnj0bEokE8fHxEAQBO3fu5F/5HdTevPj5+SE8PBweHh4wNzfH4cOHsWfPHgQFBSEhIQFmZrxHviOaCsHs7GwkJyfjiSeeQP/+/SGXyxEVFQUAGD9+PADgwIEDmu2uX7+OyMhIWFtbIyoqCtXV1YiLi4OTkxNXreig9uQkPz8fU6dORUREBNzc3DSr7qSlpSE8PBz//ve/DbMzJuCtt95CQkICHnzwQTzyyCNaz/Xu3RsTJ04EwPNKV+tIXnhe0Y+YmBhYWFggICAASqUS169fx44dO1BQUID33nsP4eHhAIz7WGGh3w2oVCq8//772LVrF8rLy+Hp6YkXXngBoaGhmjkt/ZIBjR9zr169GqmpqVCr1QgODsarr74KZ2fnrt4Nk9PevLz22ms4ceIErl+/jvr6evTr1w/h4eGYP38+b2TrBJ6eni2O9+vXT1NEtlToA8ClS5fw9ttv4/jx45BKpRg3bhyWL1/ONpEOak9OKioq8OabbyI9PR1FRUVQq9VwdXXF1KlTERMTw3smOqDp/0stuT0nPK90rY7khecV/di+fTuSkpKQlZWFiooKWFlZwd/fH3PmzMHIkSM184z5WGGhT0RERERkgtijT0RERERkgljoExERERGZIBb6REREREQmiIU+EREREZEJYqFPRERERGSCWOgTEREREZkgFvpERERERCaIhT4REZmU6OhozRdwERH1ZPxOZCIiatXhw4cRExOj83mJRILMzMwujIiIiFrDQp+IiNosIiICY8eObTYuFvMDYiIiY8NCn4iI2mzIkCGYMmWKocMgIqI24CUYIiLqNPn5+fD09MS6deuQnJyMRx99FEOHDsW4ceOwbt063Lp1q9k258+fx6JFixAcHIyhQ4ciPDwcGzduRENDQ7O5xcXF+Mc//oEJEybA19cXISEhmD17NlJTU5vNLSwsxAsvvIARI0bAz88Pzz33HHJycvSy30RExohX9ImIqM1qampQWlrabNzc3Bx9+vTRPD5w4ADy8vIwc+ZM2Nvb48CBA/jwww9x7do1rFmzRjPvzJkziI6OhpmZmWZuSkoK3n33XZw/fx7/+te/NHPz8/PxzDPPoKSkBFOmTIGvry9qamqQnp6OgwcPYtSoUZq51dXViIqKgp+fH5YuXYr8/HwkJCRg4cKFSE5OhkQi0dO/EBGR8WChT0REbbZu3TqsW7eu2fi4ceOwYcMGzePz589j+/bt8PHxAQBERUVh8eLF2LFjB6ZPnw5/f38AwFtvvYW6ujps2bIFXl5emrlLlixBcnIypk2bhpCQEADAypUrUVRUhNjYWIwZM0br/dVqtdbj33//Hc899xzmzZunGbO1tcU777yDgwcPNtueiMgUsdAnIqI2mz59OsLCwpqN29raaj0ODQ3VFPkAIBKJMHfuXOzfvx/79u2Dv78/SkpKcPLkSUyaNElT5DfNff7557F7927s27cPISEhKCsrwy+//IIxY8a0WKTfeTOwWCxutkrQ/fffDwC4evUqC30i6hFY6BMRUZu5uLggNDS01Xnu7u7NxgYNGgQAyMvLA9DYinP7+O3c3NwgFos1c3NzcyEIAoYMGdKmOB0cHGBhYaE1Zm1tDQAoKytr02sQEXV3vBmXiIhMzt168AVB6MJIiIgMh4U+ERF1uuzs7GZjWVlZAABnZ2cAQP/+/bXGb3f58mWo1WrN3AEDBkAkEuHcuXP6CpmIyOSw0Cciok538OBBnD17VvNYEATExsYCACZOnAgAsLOzQ0BAAFJSUnDx4kWtuZ988gkAYNKkSQAa227Gjh2Ln3/+GQcPHmz2frxKT0TUHHv0iYiozTIzM5GUlNTic00FPAB4eXlh1qxZmDlzJpRKJX788UccPHgQU6ZMQUBAgGbeq6++iujoaMycORMzZsyAUqlESkoKfv31V0RERGhW3AGAv//978jMzMS8efMQGRkJHx8fqFQqpKeno1+/fnjppZf0t+NERN0QC30iImqz5ORkJCcnt/jc3r17Nb3x48ePx8CBA7Fhwwbk5OTAzs4OCxcuxMKFC7W2GTp0KLZs2YIPPvgAX331Faqrq+Hs7Iy//vWvmDNnjtZcZ2dnfPPNN/joo4/w888/IykpCXK5HF5eXpg+fbp+dpiIqBsTCfy8k4iIOkl+fj4mTJiAxYsX489//rOhwyEi6tHYo09EREREZIJY6BMRERERmSAW+kREREREJog9+kREREREJohX9ImIiIiITBALfSIiIiIiE8RCn4iIiIjIBLHQJyIiIiIyQSz0iYiIiIhMEAt9IiIiIiIT9P8ijQAWd0imWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(b_input_ids, \n",
    "            token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3359,  0.2034,  0.4254, -0.0613, -0.5558, -0.0877],\n",
       "        [-0.3844,  0.3217,  0.3338, -0.0657, -0.3582, -0.1848],\n",
       "        [-0.4764,  0.0129,  0.3916, -0.2032, -0.4588, -0.1389],\n",
       "        [-0.3971,  0.1795,  0.2998, -0.0435, -0.4394, -0.1542],\n",
       "        [-0.4704,  0.1335,  0.3870, -0.1225, -0.4642, -0.1647],\n",
       "        [-0.2808,  0.2704,  0.3687, -0.2258, -0.2896, -0.0577],\n",
       "        [-0.4765,  0.1830,  0.2681, -0.1687, -0.4773, -0.1837],\n",
       "        [-0.5013,  0.0938,  0.3793, -0.1453, -0.5732, -0.2003],\n",
       "        [-0.4069,  0.1787,  0.3992, -0.1886, -0.3932, -0.0778],\n",
       "        [-0.3342,  0.4313,  0.6093, -0.1369, -0.3197, -0.2518],\n",
       "        [-0.3654,  0.4054,  0.3981, -0.1148, -0.1999, -0.1376],\n",
       "        [-0.4388, -0.0099,  0.2618, -0.2115, -0.5811, -0.1659],\n",
       "        [-0.3378,  0.1871,  0.5835,  0.0465, -0.5037, -0.0348],\n",
       "        [-0.3082, -0.0050,  0.3554, -0.1940, -0.4708, -0.0740],\n",
       "        [-0.3197, -0.2055,  0.1524, -0.3172, -0.4813, -0.0470],\n",
       "        [-0.4643,  0.3097,  0.5215, -0.0800, -0.3064, -0.1917],\n",
       "        [-0.4907,  0.3745,  0.4405, -0.0234, -0.4319, -0.1926],\n",
       "        [-0.3989,  0.1305,  0.4223, -0.1186, -0.5839, -0.2145],\n",
       "        [-0.4045,  0.2804,  0.4091, -0.0678, -0.4305, -0.2077],\n",
       "        [-0.4517,  0.1151,  0.3807, -0.0833, -0.5485, -0.1052],\n",
       "        [-0.4526,  0.2464,  0.4385, -0.1900, -0.3410, -0.1505],\n",
       "        [-0.5103,  0.0181,  0.2959, -0.1830, -0.6139, -0.2230],\n",
       "        [-0.2832,  0.4822,  0.4913, -0.0635, -0.1106, -0.1989],\n",
       "        [-0.3622, -0.0041,  0.1779, -0.2279, -0.4866, -0.0837],\n",
       "        [-0.4173,  0.2662,  0.4671, -0.1305, -0.3669, -0.1161],\n",
       "        [-0.3975, -0.0180,  0.5537, -0.1784, -0.4926, -0.0936],\n",
       "        [-0.3653, -0.2216,  0.1916, -0.3356, -0.5763, -0.1169],\n",
       "        [-0.3628,  0.1923,  0.3396, -0.1428, -0.2304, -0.3003],\n",
       "        [-0.4598,  0.1907,  0.4722, -0.1297, -0.3393, -0.1254],\n",
       "        [-0.3952, -0.1149,  0.1899, -0.2616, -0.5600, -0.1251],\n",
       "        [-0.5025,  0.1931,  0.3397, -0.1462, -0.4901, -0.2310],\n",
       "        [-0.4676, -0.0428,  0.5007, -0.1903, -0.6335, -0.1742]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 5 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a3b33b587f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m## this token type id only works for next sentence prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             labels=b_labels)\n\u001b[0m",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 5 is out of bounds."
     ]
    }
   ],
   "source": [
    "b_input_ids,attention_mask,b_labels =next(iter(train_dataloader))\n",
    "outputs = model(b_input_ids, \n",
    "            token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.LongTensor(np.array([0,1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##next part: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.65625"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "821/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([821, 256])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([821, 256])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.stack(train_inputs)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-08e540e74da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101.,  1045.,  2293.,  2122., 16324.,   999.,  2025.,  2069.,  2024.,\n",
       "         2027.,  7965.,  2021.,  2027.,  5510.,  2307.,  1998.,  2024.,  2061.,\n",
       "         3730.,   999.,  1045.,  2097.,  5791.,  5587.,  2122.,  2000.,  2026.,\n",
       "        13025.,  2862.,   999.,   102.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(input_token_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=input_token_ids[0]\n",
    "F.pad(test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((256-31)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "t4d = torch.rand([1,31])\n",
    "p1d = (int((256-31)/2)+1,int((256-31)/2)) # pad last dim by 1 on each side\n",
    "out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
    "print(out.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.pad??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_face_ENV",
   "language": "python",
   "name": "hugging_face_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
