{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>562971</td>\n",
       "      <td>I love these cookies!  Not only are they healt...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>562972</td>\n",
       "      <td>Quaker Soft Baked Oatmeal Cookies with raisins...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>562973</td>\n",
       "      <td>I am usually not a huge fan of oatmeal cookies...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562974</td>\n",
       "      <td>I participated in a product review that includ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562975</td>\n",
       "      <td>My kids loved these. I was very pleased to giv...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                               Text  Score\n",
       "0  562971  I love these cookies!  Not only are they healt...      5\n",
       "1  562972  Quaker Soft Baked Oatmeal Cookies with raisins...      5\n",
       "2  562973  I am usually not a huge fan of oatmeal cookies...      5\n",
       "3  562974  I participated in a product review that includ...      5\n",
       "4  562975  My kids loved these. I was very pleased to giv...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"Amazon_review_data/Reviews.csv\")\n",
    "reviews['ProductId']=reviews['ProductId'].astype(str)\n",
    "df=reviews[reviews['ProductId']==\"B007JFMH8M\"]  ## the most popular cookie\n",
    "df = df.reset_index(drop=True)\n",
    "df= df[['Id', 'Text', 'Score']]\n",
    "sentences=df.Text.values\n",
    "labels= df.Score.values -1  ### here is important. because the BERT classification requires the label category start from 0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load the bert model\n",
    "model = BertModel.from_pretrained('bert-base-uncased') #cache_dir='some path that I want to download the model'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) #output_hidden_states=True, output_attentions=True\n",
    "# input_ids = torch.tensor([tokenizer.encode(\"Let's see all hidden-states and attentions on this text\")])\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([804.,  90.,  10.,   5.,   2.,   1.,   0.,   0.,   0.,   1.]),\n",
       " array([  21. ,  122.6,  224.2,  325.8,  427.4,  529. ,  630.6,  732.2,\n",
       "         833.8,  935.4, 1037. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_counts=[len(tokenizer.tokenize(sent)) for sent in sentences]\n",
    "print(sum(np.array(tokens_counts)>256))\n",
    "plt.hist(tokens_counts)  ## most texts is shorted than 400 tokens, we select 256 as the max_len of our sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  I love these cookies!  Not only are they healthy but they taste great and are so soft!  I will definitely add these to my grocery list!\n",
      "Tokenized:  ['i', 'love', 'these', 'cookies', '!', 'not', 'only', 'are', 'they', 'healthy', 'but', 'they', 'taste', 'great', 'and', 'are', 'so', 'soft', '!', 'i', 'will', 'definitely', 'add', 'these', 'to', 'my', 'grocery', 'list', '!']\n",
      "Token IDs:  [1045, 2293, 2122, 16324, 999, 2025, 2069, 2024, 2027, 7965, 2021, 2027, 5510, 2307, 1998, 2024, 2061, 3730, 999, 1045, 2097, 5791, 5587, 2122, 2000, 2026, 13025, 2862, 999]\n",
      "Token IDs aftern encoding:  [101, 1045, 2293, 2122, 16324, 999, 2025, 2069, 2024, 2027, 7965, 2021, 2027, 5510, 2307, 1998, 2024, 2061, 3730, 999, 1045, 2097, 5791, 5587, 2122, 2000, 2026, 13025, 2862, 999, 102]\n"
     ]
    }
   ],
   "source": [
    "input_token_ids=[]\n",
    "for sent in sentences:\n",
    "    input_token_ids.append(tokenizer.encode(sent,                         \n",
    "                            max_length = 256))      # Truncate all sentences.\n",
    "#                             return_tensors = 'pt'))     # Return pytorch tensors.\n",
    "\n",
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n",
    "\n",
    "## tokenize.encode can handle both two steps above, and then add special tokens [start] and [end]\n",
    "print('Token IDs aftern encoding: ', tokenizer.encode(sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  256\n",
      "Min sentence length:  23\n"
     ]
    }
   ],
   "source": [
    "## max length of the reviews:\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_token_ids]))\n",
    "print('Min sentence length: ', min([len(sen) for sen in input_token_ids]))  ##padding has not been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 256 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Padding added done\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 256\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids=[]\n",
    "for sent in input_token_ids:\n",
    "    input_ids.append(F.pad(torch.tensor(sent, dtype=torch.long), (0, int(MAX_LEN-len(sent))), \"constant\", 0))\n",
    "print('\\nPadding added done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(torch.tensor(np.array(att_mask), dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=110, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=110, test_size=0.1)\n",
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.stack(train_inputs)  ##convert a list of tensors into a tensor\n",
    "validation_inputs = torch.stack(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long) ## convert an array to a tensor\n",
    "validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n",
    "\n",
    "train_masks = torch.stack(train_masks)\n",
    "validation_masks = torch.stack(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# model.cuda() same thing\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (5, 768)\n",
      "classifier.bias                                                 (5,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "# transformers.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, num_cycles=0.5, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/home/ec2-user/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff8cd4134a8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the purposes of fine-tuning, the authors recommend choosing from the following values:\n",
    "# - Batch size: 16, 32  (We chose 32 when creating our DataLoaders).\n",
    "# - Learning rate (Adam): 5e-5, 3e-5, 2e-5  (We'll use 2e-5).\n",
    "# - Number of epochs: 2, 3, 4  (We'll use 4).\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "#'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 9e-3, # args.learning_rate - default is 5e-5\n",
    "                  eps =1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps,\n",
    "                                            num_cycles=0.5, last_epoch=-1)\n",
    "##plot the lrs\n",
    "lrs=[]\n",
    "for i in range(100):\n",
    "    lrs.append(scheduler.get_lr()) \n",
    "    scheduler.step()\n",
    "plt.plot(range(100), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the training and evaluation loop:\n",
    "\n",
    "Training loop:\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "Evalution loop:\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "So please read carefully through the comments to get an understanding of what's happening. If you're unfamiliar with pytorch a quick look at some of their [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) will help show you that training loops really involve only a few simple steps; the rest is usually just decoration and logging.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten() \n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:50.\n",
      "\n",
      "  Average training loss: 1.04\n",
      "  Training epcoh took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "sample validation\n",
      "[[-3.388062  -1.836984  -1.6624957  1.5288981  1.7407618]\n",
      " [-3.3880646 -1.8369801 -1.6624967  1.5288965  1.74076  ]\n",
      " [-3.3880591 -1.8369834 -1.6624931  1.5288981  1.7407614]]\n",
      "[4 4 4]\n",
      "sample validation\n",
      "[[-3.3880653 -1.8369831 -1.6624986  1.5288974  1.7407606]\n",
      " [-3.3880634 -1.8369864 -1.6625061  1.5288981  1.7407614]\n",
      " [-3.3880594 -1.836982  -1.6624962  1.5288974  1.7407614]]\n",
      "[4 3 3]\n",
      "sample validation\n",
      "[[-3.3880656 -1.83698   -1.662506   1.528895   1.7407584]\n",
      " [-3.388059  -1.8369848 -1.6624955  1.5288991  1.740763 ]\n",
      " [-3.388053  -1.8369882 -1.6624947  1.5288998  1.740763 ]]\n",
      "[4 3 4]\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss: 1.54\n",
      "  Training epcoh took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "sample validation\n",
      "[[-0.5319531   0.4555112  -2.3689868  -3.5873415   2.561892  ]\n",
      " [-0.531946    0.45551342 -2.368985   -3.587345    2.5618885 ]\n",
      " [-0.53195083  0.4555118  -2.3689864  -3.5873435   2.561891  ]]\n",
      "[4 4 4]\n",
      "sample validation\n",
      "[[-0.53194475  0.45551395 -2.3689845  -3.5873451   2.5618882 ]\n",
      " [-0.53194624  0.4555133  -2.3689845  -3.5873442   2.5618885 ]\n",
      " [-0.5319448   0.45551395 -2.368985   -3.587345    2.5618885 ]]\n",
      "[4 3 3]\n",
      "sample validation\n",
      "[[-0.53195184  0.45551157 -2.3689864  -3.5873423   2.5618918 ]\n",
      " [-0.531946    0.4555136  -2.3689852  -3.5873442   2.5618882 ]\n",
      " [-0.5319563   0.45551032 -2.368987   -3.5873406   2.5618927 ]]\n",
      "[4 3 4]\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n",
      "  Batch    20  of     26.    Elapsed: 0:00:51.\n",
      "\n",
      "  Average training loss: 1.81\n",
      "  Training epcoh took: 0:01:05\n",
      "\n",
      "Running Validation...\n",
      "sample validation\n",
      "[[-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152102  -2.0994005   4.8437157   6.848502 ]]\n",
      "[4 4 4]\n",
      "sample validation\n",
      "[[-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152104  -2.0994005   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]]\n",
      "[4 3 3]\n",
      "sample validation\n",
      "[[-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152102  -2.0994008   4.843715    6.848502 ]\n",
      " [-26.17407    -1.7152102  -2.0994005   4.843715    6.848502 ]]\n",
      "[4 3 4]\n",
      "  Accuracy: 0.65\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:00:25.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3a06cee4f753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#   [1]: attention masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#   [2]: labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mb_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mb_input_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "## the training loop is based on\n",
    "## https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "seed_val = 10\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 10 batches. (one epoch has 26 batches)\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        loss = outputs[0] # (loss), logits, (hidden_states), (attentions) \n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        print('sample validation')\n",
    "        print(logits[0:3])\n",
    "        print(label_ids[0:3])\n",
    "\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache() ## clear all cache memory in GPU or restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(validation_labels.numpy()==4)/len(validation_labels.numpy())\n",
    "### that's why in the validation, accuracy is alway 0.65. It just predict all the labels to be label 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important takeaway is that lr here should be larger than default. I use max_lr=9*10e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(b_input_ids, \n",
    "            token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3359,  0.2034,  0.4254, -0.0613, -0.5558, -0.0877],\n",
       "        [-0.3844,  0.3217,  0.3338, -0.0657, -0.3582, -0.1848],\n",
       "        [-0.4764,  0.0129,  0.3916, -0.2032, -0.4588, -0.1389],\n",
       "        [-0.3971,  0.1795,  0.2998, -0.0435, -0.4394, -0.1542],\n",
       "        [-0.4704,  0.1335,  0.3870, -0.1225, -0.4642, -0.1647],\n",
       "        [-0.2808,  0.2704,  0.3687, -0.2258, -0.2896, -0.0577],\n",
       "        [-0.4765,  0.1830,  0.2681, -0.1687, -0.4773, -0.1837],\n",
       "        [-0.5013,  0.0938,  0.3793, -0.1453, -0.5732, -0.2003],\n",
       "        [-0.4069,  0.1787,  0.3992, -0.1886, -0.3932, -0.0778],\n",
       "        [-0.3342,  0.4313,  0.6093, -0.1369, -0.3197, -0.2518],\n",
       "        [-0.3654,  0.4054,  0.3981, -0.1148, -0.1999, -0.1376],\n",
       "        [-0.4388, -0.0099,  0.2618, -0.2115, -0.5811, -0.1659],\n",
       "        [-0.3378,  0.1871,  0.5835,  0.0465, -0.5037, -0.0348],\n",
       "        [-0.3082, -0.0050,  0.3554, -0.1940, -0.4708, -0.0740],\n",
       "        [-0.3197, -0.2055,  0.1524, -0.3172, -0.4813, -0.0470],\n",
       "        [-0.4643,  0.3097,  0.5215, -0.0800, -0.3064, -0.1917],\n",
       "        [-0.4907,  0.3745,  0.4405, -0.0234, -0.4319, -0.1926],\n",
       "        [-0.3989,  0.1305,  0.4223, -0.1186, -0.5839, -0.2145],\n",
       "        [-0.4045,  0.2804,  0.4091, -0.0678, -0.4305, -0.2077],\n",
       "        [-0.4517,  0.1151,  0.3807, -0.0833, -0.5485, -0.1052],\n",
       "        [-0.4526,  0.2464,  0.4385, -0.1900, -0.3410, -0.1505],\n",
       "        [-0.5103,  0.0181,  0.2959, -0.1830, -0.6139, -0.2230],\n",
       "        [-0.2832,  0.4822,  0.4913, -0.0635, -0.1106, -0.1989],\n",
       "        [-0.3622, -0.0041,  0.1779, -0.2279, -0.4866, -0.0837],\n",
       "        [-0.4173,  0.2662,  0.4671, -0.1305, -0.3669, -0.1161],\n",
       "        [-0.3975, -0.0180,  0.5537, -0.1784, -0.4926, -0.0936],\n",
       "        [-0.3653, -0.2216,  0.1916, -0.3356, -0.5763, -0.1169],\n",
       "        [-0.3628,  0.1923,  0.3396, -0.1428, -0.2304, -0.3003],\n",
       "        [-0.4598,  0.1907,  0.4722, -0.1297, -0.3393, -0.1254],\n",
       "        [-0.3952, -0.1149,  0.1899, -0.2616, -0.5600, -0.1251],\n",
       "        [-0.5025,  0.1931,  0.3397, -0.1462, -0.4901, -0.2310],\n",
       "        [-0.4676, -0.0428,  0.5007, -0.1903, -0.6335, -0.1742]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 5 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a3b33b587f9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m## this token type id only works for next sentence prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             labels=b_labels)\n\u001b[0m",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 916\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Ben/text_summarization_and_NLP/hugging_face_Transformer_ENV/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1836\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 5 is out of bounds."
     ]
    }
   ],
   "source": [
    "b_input_ids,attention_mask,b_labels =next(iter(train_dataloader))\n",
    "outputs = model(b_input_ids, \n",
    "            token_type_ids=None, ## this token type id only works for next sentence prediction\n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.LongTensor(np.array([0,1,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##next part: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.65625"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "821/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([821, 256])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([821, 256])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.stack(train_inputs)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-08e540e74da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidation_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101.,  1045.,  2293.,  2122., 16324.,   999.,  2025.,  2069.,  2024.,\n",
       "         2027.,  7965.,  2021.,  2027.,  5510.,  2307.,  1998.,  2024.,  2061.,\n",
       "         3730.,   999.,  1045.,  2097.,  5791.,  5587.,  2122.,  2000.,  2026.,\n",
       "        13025.,  2862.,   999.,   102.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(input_token_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=input_token_ids[0]\n",
    "F.pad(test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((256-31)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "t4d = torch.rand([1,31])\n",
    "p1d = (int((256-31)/2)+1,int((256-31)/2)) # pad last dim by 1 on each side\n",
    "out = F.pad(t4d, p1d, \"constant\", 0)  # effectively zero padding\n",
    "print(out.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.pad??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging_face_ENV",
   "language": "python",
   "name": "hugging_face_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
